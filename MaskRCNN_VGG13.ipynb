{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLccje4bGPNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edca679d-461a-46b9-c4ec-4f9756d57aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mask_rcnn_vgg13_wbc_colab.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mask_rcnn_vgg13_wbc_colab.py\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import os, sys, gc, time, math, csv, random\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import amp\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import torchvision\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "from torchvision.models import ResNet101_Weights\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "from collections import OrderedDict\n",
        "from torchvision.models._utils import IntermediateLayerGetter\n",
        "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool\n",
        "from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
        "from torchvision.models import (\n",
        "    VGG11_Weights, VGG13_Weights, VGG16_Weights, VGG19_Weights\n",
        ")\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "DBG_OVERFIT_TINY   = False\n",
        "DBG_USE_GT_PROPOSALS = False\n",
        "DBG_SKIP_NMS       = False\n",
        "DBG_SCORE_THR      = 0.0\n",
        "\n",
        "\n",
        "def set_torch_threads(n=4):\n",
        "    os.environ.setdefault(\"OMP_NUM_THREADS\", str(n))\n",
        "    os.environ.setdefault(\"MKL_NUM_THREADS\", str(n))\n",
        "    try:\n",
        "        torch.set_float32_matmul_precision(\"medium\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def coco_xywh_to_xyxy(box):\n",
        "    x, y, w, h = box\n",
        "    return [x, y, x + w, y + h]\n",
        "\n",
        "\n",
        "def clamp_box_xyxy(box, W, H):\n",
        "    x1, y1, x2, y2 = box\n",
        "    x1 = max(0, min(int(x1), W - 1))\n",
        "    y1 = max(0, min(int(y1), H - 1))\n",
        "    x2 = max(0, min(int(x2), W - 1))\n",
        "    y2 = max(0, min(int(y2), H - 1))\n",
        "    if x2 <= x1:\n",
        "        x2 = min(W - 1, x1 + 1)\n",
        "    if y2 <= y1:\n",
        "        y2 = min(H - 1, y1 + 1)\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "\n",
        "def box_iou_xyxy(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0]); yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2]); yB = min(boxA[3], boxB[3])\n",
        "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if inter <= 0:\n",
        "        return 0.0\n",
        "    areaA = max(0, boxA[2]-boxA[0]) * max(0, boxA[3]-boxA[1])\n",
        "    areaB = max(0, boxB[2]-boxB[0]) * max(0, boxB[3]-boxB[1])\n",
        "    return inter / (areaA + areaB - inter + 1e-6)\n",
        "\n",
        "\n",
        "def greedy_match_accuracy(pred, gt, iou_thr=0.5):\n",
        "    p_boxes = pred[\"boxes\"].cpu().numpy()\n",
        "    p_labels = pred[\"labels\"].cpu().numpy()\n",
        "    p_scores = pred[\"scores\"].cpu().numpy()\n",
        "    order = p_scores.argsort()[::-1]\n",
        "    p_boxes = p_boxes[order]; p_labels = p_labels[order]\n",
        "\n",
        "    g_boxes = gt[\"boxes\"].cpu().numpy()\n",
        "    g_labels = gt[\"labels\"].cpu().numpy()\n",
        "    matched = set()\n",
        "    hits = 0\n",
        "    for pb, pl in zip(p_boxes, p_labels):\n",
        "        best_iou, best_j = 0.0, -1\n",
        "        for j,(gb,gl) in enumerate(zip(g_boxes, g_labels)):\n",
        "            if j in matched:\n",
        "                continue\n",
        "            iou = box_iou_xyxy(pb, gb)\n",
        "            if iou > best_iou:\n",
        "                best_iou, best_j = iou, j\n",
        "        if best_j >= 0 and best_iou >= iou_thr and pl == g_labels[best_j]:\n",
        "            matched.add(best_j)\n",
        "            hits += 1\n",
        "    return hits / max(1, len(g_boxes))\n",
        "\n",
        "def get_gpu_temp(gpu_index: int = 0):\n",
        "    try:\n",
        "        import subprocess\n",
        "        out = subprocess.check_output(\n",
        "            ['nvidia-smi', f'--id={gpu_index}',\n",
        "             '--query-gpu=temperature.gpu', '--format=csv,noheader,nounits'],\n",
        "            stderr=subprocess.DEVNULL\n",
        "        ).decode().strip()\n",
        "        return int(out)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def cool_if_hot(threshold: int = 85, resume: int = 80, sleep_s: int = 10, gpu_index: int = 0):\n",
        "    temp = get_gpu_temp(gpu_index)\n",
        "    if temp is None:\n",
        "        return False\n",
        "    tripped = False\n",
        "    while temp is not None and temp >= threshold:\n",
        "        tripped = True\n",
        "        print(f\"GPU {gpu_index} = {temp}°C ≥ {threshold}°C\", flush=True)\n",
        "        try:\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "                torch.cuda.empty_cache()\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(sleep_s)\n",
        "        temp = get_gpu_temp(gpu_index)\n",
        "    if tripped:\n",
        "        print(f\"Continue Training\", flush=True)\n",
        "    return tripped\n",
        "\n",
        "\n",
        "# ====== Dataset ======\n",
        "class CocoInstanceDataset(Dataset):\n",
        "    def __init__(self, root_split: str, transforms=None, category_id_mapping: Dict[int, int] = None):\n",
        "        self.root = Path(root_split)\n",
        "        self.img_dir = self.root / \"images\"\n",
        "        self.ann_file = self.root / \"annotations.json\"\n",
        "        assert self.img_dir.is_dir(), f\"images folder not found: {self.img_dir}\"\n",
        "        assert self.ann_file.is_file(), f\"annotations.json not found: {self.ann_file}\"\n",
        "\n",
        "        self.coco = COCO(str(self.ann_file))\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "        self.transforms = transforms\n",
        "\n",
        "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
        "        self.catid_to_name = {c[\"id\"]: c[\"name\"] for c in cats}\n",
        "\n",
        "        if category_id_mapping is None:\n",
        "            sorted_cat_ids = sorted(self.catid_to_name.keys())\n",
        "            self.catid_to_contig = {cid: i+1 for i, cid in enumerate(sorted_cat_ids)}\n",
        "        else:\n",
        "            self.catid_to_contig = dict(category_id_mapping)\n",
        "\n",
        "        self.contig_to_name = {v: self.catid_to_name[k] for k, v in self.catid_to_contig.items()}\n",
        "\n",
        "    @property\n",
        "    def classes(self) -> List[str]:\n",
        "        num = len(self.catid_to_contig)\n",
        "        arr = ['__background__'] + [self.contig_to_name[i] for i in range(1, num+1)]\n",
        "        return arr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img_id = self.ids[index]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        img_path = self.img_dir / img_info[\"file_name\"]\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        W, H = image.size\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "\n",
        "        boxes, labels, masks, area, iscrowd = [], [], [], [], []\n",
        "\n",
        "        for ann in anns:\n",
        "            if \"bbox\" not in ann:\n",
        "                continue\n",
        "            xyxy = clamp_box_xyxy(coco_xywh_to_xyxy(ann[\"bbox\"]), W, H)\n",
        "            boxes.append(xyxy)\n",
        "            cat_id = ann[\"category_id\"]\n",
        "            labels.append(self.catid_to_contig[cat_id])\n",
        "\n",
        "            m = self.coco.annToMask(ann)\n",
        "            masks.append(m)\n",
        "\n",
        "            area.append(ann.get(\"area\", float((xyxy[2]-xyxy[0]) * (xyxy[3]-xyxy[1]))))\n",
        "            iscrowd.append(ann.get(\"iscrowd\", 0))\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "            masks = torch.zeros((0, H, W), dtype=torch.uint8)\n",
        "            area = torch.zeros((0,), dtype=torch.float32)\n",
        "            iscrowd = torch.zeros((0,), dtype=torch.uint8)\n",
        "        else:\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            masks = torch.as_tensor(np.stack(masks, axis=0), dtype=torch.uint8)\n",
        "            area = torch.as_tensor(area, dtype=torch.float32)\n",
        "            iscrowd = torch.as_tensor(iscrowd, dtype=torch.uint8)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"masks\": masks,\n",
        "            \"image_id\": torch.tensor([img_id], dtype=torch.int64),\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": iscrowd,\n",
        "        }\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image, target = self.transforms(image, target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "# ====== Transforms ======\n",
        "class ToTensor:\n",
        "    def __call__(self, image, target):\n",
        "        return F.to_tensor(image), target\n",
        "\n",
        "class NormalizeDet:\n",
        "    def __init__(self, mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)):\n",
        "        self.mean = mean; self.std = std\n",
        "    def __call__(self, image, target):\n",
        "        image = (image - torch.tensor(self.mean)[:,None,None]) / torch.tensor(self.std)[:,None,None]\n",
        "        return image, target\n",
        "\n",
        "class AlbumentationsDet:\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "        self.geom = A.Compose([\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.1, rotate_limit=10,\n",
        "                               border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
        "        ], bbox_params=A.BboxParams(\n",
        "            format=\"pascal_voc\",\n",
        "            label_fields=[\"labels\"],\n",
        "            min_visibility=0.2\n",
        "        ))\n",
        "        self.img_only = A.Compose([\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=10, p=0.3),\n",
        "            A.GaussNoise(var_limit=(5.0, 20.0), p=0.2),\n",
        "            A.GaussianBlur(blur_limit=3, p=0.2),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        if random.random() > self.p:\n",
        "            return image, target\n",
        "\n",
        "        img = np.array(image)\n",
        "        boxes = target[\"boxes\"].numpy() if target[\"boxes\"].numel() > 0 else np.zeros((0,4), dtype=np.float32)\n",
        "        labels = target[\"labels\"].numpy() if target[\"labels\"].numel() > 0 else np.zeros((0,), dtype=np.int64)\n",
        "        masks  = target[\"masks\"].numpy()  if target[\"masks\"].numel()  > 0 else np.zeros((0, img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "\n",
        "        img = self.img_only(image=img)[\"image\"]\n",
        "\n",
        "        if boxes.shape[0] == 0:\n",
        "            from PIL import Image\n",
        "            return Image.fromarray(img), target\n",
        "\n",
        "        bboxes_list = boxes.tolist()\n",
        "        masks_list  = [m for m in masks]\n",
        "\n",
        "        out = self.geom(image=img, bboxes=bboxes_list, labels=labels.tolist(), masks=masks_list)\n",
        "        img_aug = out[\"image\"]\n",
        "        boxes_aug = np.array(out[\"bboxes\"], dtype=np.float32) if len(out[\"bboxes\"]) > 0 else np.zeros((0, 4), dtype=np.float32)\n",
        "        labels_aug = np.array(out[\"labels\"], dtype=np.int64)   if len(out[\"labels\"]) > 0 else np.zeros((0,), dtype=np.int64)\n",
        "\n",
        "        if len(out[\"masks\"]) > 0:\n",
        "            if isinstance(out[\"masks\"], np.ndarray) and out[\"masks\"].ndim == 2:\n",
        "                masks_aug = out[\"masks\"][None, ...].astype(np.uint8)\n",
        "            else:\n",
        "                masks_aug = np.stack(out[\"masks\"], axis=0).astype(np.uint8)\n",
        "        else:\n",
        "            masks_aug = np.zeros((0, img_aug.shape[0], img_aug.shape[1]), dtype=np.uint8)\n",
        "\n",
        "        if boxes_aug.shape[0] > 0:\n",
        "            valid = (boxes_aug[:, 2] > boxes_aug[:, 0]) & (boxes_aug[:, 3] > boxes_aug[:, 1])\n",
        "            boxes_aug  = boxes_aug[valid]\n",
        "            labels_aug = labels_aug[valid]\n",
        "            if masks_aug.shape[0] != boxes_aug.shape[0]:\n",
        "                n = min(masks_aug.shape[0], boxes_aug.shape[0])\n",
        "                boxes_aug  = boxes_aug[:n]\n",
        "                labels_aug = labels_aug[:n]\n",
        "                masks_aug  = masks_aug[:n] if n > 0 else np.zeros((0, img_aug.shape[0], img_aug.shape[1]), dtype=np.uint8)\n",
        "            else:\n",
        "                masks_aug = masks_aug[valid]\n",
        "            H, W = img_aug.shape[:2]\n",
        "            boxes_aug = np.clip(boxes_aug, 0, max(H, W))\n",
        "\n",
        "        import torch\n",
        "        target[\"boxes\"]  = torch.as_tensor(boxes_aug, dtype=torch.float32)\n",
        "        target[\"labels\"] = torch.as_tensor(labels_aug, dtype=torch.int64)\n",
        "        target[\"masks\"]  = torch.as_tensor(masks_aug, dtype=torch.uint8)\n",
        "\n",
        "        if target[\"boxes\"].numel() > 0:\n",
        "            xyxy = target[\"boxes\"]\n",
        "            area = (xyxy[:,2]-xyxy[:,0]).clamp(min=0) * (xyxy[:,3]-xyxy[:,1]).clamp(min=0)\n",
        "            target[\"area\"] = area.to(torch.float32)\n",
        "        else:\n",
        "            target[\"area\"] = torch.zeros((0,), dtype=torch.float32)\n",
        "\n",
        "        from PIL import Image\n",
        "        image = Image.fromarray(img_aug)\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class ComposeDet:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "\n",
        "def get_transform(train: bool, aug_prob=0.0):\n",
        "    if train:\n",
        "        tr = [\n",
        "            AlbumentationsDet(p=aug_prob),\n",
        "            ToTensor(),\n",
        "            NormalizeDet(),\n",
        "        ]\n",
        "    else:\n",
        "        tr = [ToTensor(), NormalizeDet()]\n",
        "    return ComposeDet(tr)\n",
        "\n",
        "\n",
        "# ====== model ======\n",
        "_VGG_WEIGHTS = {\n",
        "    \"vgg11\": VGG11_Weights.IMAGENET1K_V1,\n",
        "    \"vgg13\": VGG13_Weights.IMAGENET1K_V1,\n",
        "    \"vgg16\": VGG16_Weights.IMAGENET1K_V1,\n",
        "    \"vgg19\": VGG19_Weights.IMAGENET1K_V1,\n",
        "}\n",
        "\n",
        "def _build_vgg_with_fpn(vgg_name: str,\n",
        "                        pretrained: bool = True,\n",
        "                        trainable_layers: int = 3,\n",
        "                        out_channels: int = 256) -> nn.Module:\n",
        "    vgg_name = vgg_name.lower()\n",
        "    if vgg_name not in _VGG_WEIGHTS:\n",
        "        raise ValueError(f\"Unsupported VGG backbone: {vgg_name}\")\n",
        "\n",
        "    weights = _VGG_WEIGHTS[vgg_name] if pretrained else None\n",
        "    vgg = getattr(torchvision.models, vgg_name)(weights=weights)\n",
        "\n",
        "    pool_idx = [i for i, m in enumerate(vgg.features) if isinstance(m, nn.MaxPool2d)]\n",
        "\n",
        "    assert len(pool_idx) == 5, f\"Unexpected number of MaxPool in {vgg_name}: {pool_idx}\"\n",
        "\n",
        "    c2, c3, c4, c5 = pool_idx[1], pool_idx[2], pool_idx[3], pool_idx[4]\n",
        "\n",
        "    in_channels_list = [128, 256, 512, 512]\n",
        "\n",
        "    blocks = []\n",
        "    start = 0\n",
        "    for p in pool_idx:\n",
        "        blocks.append((start, p))\n",
        "        start = p + 1\n",
        "\n",
        "    num_blocks = 5\n",
        "    tl = max(0, min(trainable_layers, num_blocks))\n",
        "\n",
        "    train_blocks = set(range(num_blocks - tl, num_blocks))\n",
        "\n",
        "    for bi, (s, e) in enumerate(blocks):\n",
        "        req = bi in train_blocks\n",
        "        for k in range(s, e + 1):\n",
        "            for p in vgg.features[k].parameters():\n",
        "                p.requires_grad = req\n",
        "\n",
        "    return_layers = {\n",
        "        str(c2): \"0\",\n",
        "        str(c3): \"1\",\n",
        "        str(c4): \"2\",\n",
        "        str(c5): \"3\",\n",
        "    }\n",
        "\n",
        "\n",
        "    backbone = BackboneWithFPN(\n",
        "        backbone=vgg.features,\n",
        "        return_layers=return_layers,\n",
        "        in_channels_list=in_channels_list,\n",
        "        out_channels=out_channels,\n",
        "        extra_blocks=LastLevelMaxPool()\n",
        "    )\n",
        "\n",
        "    backbone.out_channels = out_channels\n",
        "    return backbone\n",
        "\n",
        "def get_mask_rcnn_vgg(vgg_name: str,\n",
        "                      num_classes: int,\n",
        "                      trainable_layers: int = 3,\n",
        "                      pretrained_backbone: bool = True,\n",
        "                      fpn_out_channels: int = 256) -> MaskRCNN:\n",
        "    backbone = _build_vgg_with_fpn(\n",
        "        vgg_name=vgg_name,\n",
        "        pretrained=pretrained_backbone,\n",
        "        trainable_layers=trainable_layers,\n",
        "        out_channels=fpn_out_channels\n",
        "    )\n",
        "    model = MaskRCNN(backbone, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def forward_with_switches(model, images, targets=None):\n",
        "    images = list(img for img in images)\n",
        "    original_image_sizes = [im.shape[-2:] for im in images]\n",
        "    images, targets = model.transform(images, targets)\n",
        "    features = model.backbone(images.tensors)\n",
        "\n",
        "    if DBG_USE_GT_PROPOSALS and targets is not None:\n",
        "        proposals = [t[\"boxes\"] for t in targets]\n",
        "        proposal_losses = {}\n",
        "    else:\n",
        "        proposals, proposal_losses = model.rpn(images, features, targets)\n",
        "\n",
        "    detections, detector_losses = model.roi_heads(\n",
        "        features, proposals, images.image_sizes, targets\n",
        "    )\n",
        "    detections = model.transform.postprocess(detections, images.image_sizes, original_image_sizes)\n",
        "\n",
        "    if DBG_SCORE_THR > 0.0:\n",
        "        for d in detections:\n",
        "            keep = d[\"scores\"] >= DBG_SCORE_THR\n",
        "            for k in (\"boxes\", \"scores\", \"labels\"):\n",
        "                d[k] = d[k][keep]\n",
        "\n",
        "    losses = {}\n",
        "    losses.update(proposal_losses)\n",
        "    losses.update(detector_losses)\n",
        "    return detections, losses\n",
        "\n",
        "\n",
        "def enhance_classification_head(model, num_classes):\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    class StrongerPredictor(nn.Module):\n",
        "        def __init__(self, in_channels, num_classes):\n",
        "            super().__init__()\n",
        "            hidden = 1024\n",
        "            self.fc1 = nn.Linear(in_channels, hidden)\n",
        "            self.relu1 = nn.ReLU(inplace=True)\n",
        "            self.fc2 = nn.Linear(hidden, hidden)\n",
        "            self.relu2 = nn.ReLU(inplace=True)\n",
        "            self.cls_score = nn.Linear(hidden, num_classes)\n",
        "            self.bbox_pred = nn.Linear(hidden, num_classes * 4)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.fc2(x)\n",
        "            x = self.relu2(x)\n",
        "            scores = self.cls_score(x)\n",
        "            bbox_deltas = self.bbox_pred(x)\n",
        "            return scores, bbox_deltas\n",
        "\n",
        "    model.roi_heads.box_predictor = StrongerPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def optimize_model_parameters(model):\n",
        "    model.rpn.pre_nms_top_n_train = 2000\n",
        "    model.rpn.post_nms_top_n_train = 1000\n",
        "    model.rpn.pre_nms_top_n_test = 1000\n",
        "    model.rpn.post_nms_top_n_test = 500\n",
        "    model.rpn.nms_thresh = 0.7\n",
        "\n",
        "    model.roi_heads.batch_size_per_image = 256\n",
        "    model.roi_heads.positive_fraction = 0.5\n",
        "    model.roi_heads.score_thresh = 0.05\n",
        "    model.roi_heads.nms_thresh = 0.5\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_optimizer_and_scheduler(model, lr=0.002):\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "    scheduler = lr_scheduler.MultiStepLR(\n",
        "        optimizer,\n",
        "        milestones=[15, 30, 45],\n",
        "        gamma=0.5\n",
        "    )\n",
        "    return optimizer, scheduler\n",
        "\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, scaler, accum_steps: int = 2):\n",
        "    model.train()\n",
        "    running = {\"loss\": 0.0, \"cls\": 0.0, \"box_reg\": 0.0, \"mask\": 0.0, \"obj\": 0.0, \"rpn_box\": 0.0}\n",
        "    n = 0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    pbar = tqdm(data_loader, desc=\"Train\", dynamic_ncols=True, leave=False, position=0)\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    for step, (images, targets) in enumerate(pbar, 1):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        cool_if_hot(threshold=83, resume=78, sleep_s=10, gpu_index=0)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            _, loss_dict = forward_with_switches(model, images, targets)\n",
        "\n",
        "            losses = (\n",
        "                loss_dict.get(\"loss_classifier\",    0.0) +\n",
        "                loss_dict.get(\"loss_box_reg\",       0.0) +\n",
        "                loss_dict.get(\"loss_mask\",          0.0) +\n",
        "                loss_dict.get(\"loss_objectness\",    0.0) +\n",
        "                loss_dict.get(\"loss_rpn_box_reg\",   0.0)\n",
        "            )\n",
        "\n",
        "            loss_value = sum(\n",
        "                (float(v.item()) if torch.is_tensor(v) else float(v))\n",
        "                for v in loss_dict.values()\n",
        "            )\n",
        "            running[\"loss\"] += loss_value\n",
        "\n",
        "        loss_scaled = losses / accum_steps\n",
        "        scaler.scale(loss_scaled).backward()\n",
        "        if step % accum_steps == 0:\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            cool_if_hot(threshold=83, resume=78, sleep_s=10, gpu_index=0)\n",
        "\n",
        "        n += 1\n",
        "        running[\"cls\"]     += loss_dict.get(\"loss_classifier\",    torch.tensor(0.0, device=device)).item()\n",
        "        running[\"box_reg\"] += loss_dict.get(\"loss_box_reg\",       torch.tensor(0.0, device=device)).item()\n",
        "        running[\"mask\"]    += loss_dict.get(\"loss_mask\",          torch.tensor(0.0, device=device)).item()\n",
        "        running[\"obj\"]     += loss_dict.get(\"loss_objectness\",    torch.tensor(0.0, device=device)).item()\n",
        "        running[\"rpn_box\"] += loss_dict.get(\"loss_rpn_box_reg\",   torch.tensor(0.0, device=device)).item()\n",
        "\n",
        "        pbar.set_postfix(loss=f\"{running['loss']/n:.4f}\")\n",
        "    for k in running: running[k] /= max(1, n)\n",
        "    return running\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate_losses(model, loader, device):\n",
        "    was_training = model.training\n",
        "    model.train(True)\n",
        "\n",
        "    running = 0.0\n",
        "    n = 0\n",
        "    last_keys = None\n",
        "\n",
        "    for images, targets in loader:\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        _, loss_dict = forward_with_switches(model, images, targets)\n",
        "        loss_val = 0.0\n",
        "        for k in (\"loss_classifier\", \"loss_box_reg\", \"loss_mask\", \"loss_objectness\", \"loss_rpn_box_reg\"):\n",
        "            v = loss_dict.get(k, 0.0)\n",
        "            loss_val += float(v) if isinstance(v, (float, int)) else float(v.item())\n",
        "        running += loss_val\n",
        "        n += 1\n",
        "        last_keys = list(loss_dict.keys())\n",
        "\n",
        "    model.train(was_training)\n",
        "    return {\"loss\": running / max(n, 1)}\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate_fg_top1(model, data_loader, device,\n",
        "                     iou_thr=0.5, score_thr=0.3, max_batches=None, desc=\"FG Top-1\"):\n",
        "    from torchvision.ops import box_iou\n",
        "\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    matched_total = 0\n",
        "    matched_correct = 0\n",
        "    seen = 0\n",
        "    TOPK = 300\n",
        "\n",
        "    for images, targets in tqdm(data_loader, desc=desc, dynamic_ncols=True):\n",
        "        seen += 1\n",
        "        if (max_batches is not None) and (seen > max_batches):\n",
        "            break\n",
        "\n",
        "        images = [img.to(device) for img in images]\n",
        "        cool_if_hot(threshold=83, resume=78, sleep_s=10, gpu_index=0)\n",
        "        outs = model(images)\n",
        "        torch.cuda.synchronize()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        for out, gt in zip(outs, targets):\n",
        "            if gt[\"boxes\"].numel() == 0 or out[\"boxes\"].numel() == 0:\n",
        "                continue\n",
        "\n",
        "            scores = out[\"scores\"].detach().cpu()\n",
        "            keep = scores >= score_thr\n",
        "            if keep.sum().item() == 0:\n",
        "                continue\n",
        "\n",
        "            boxes_p  = out[\"boxes\"].detach().cpu()[keep]\n",
        "            labels_p = out[\"labels\"].detach().cpu()[keep]\n",
        "            scores_p = scores[keep]\n",
        "\n",
        "            if scores_p.numel() > TOPK:\n",
        "                vals, idx = torch.topk(scores_p, TOPK)\n",
        "                boxes_p, labels_p, scores_p = boxes_p[idx], labels_p[idx], vals\n",
        "\n",
        "            boxes_g  = gt[\"boxes\"].detach().cpu()\n",
        "            labels_g = gt[\"labels\"].detach().cpu()\n",
        "            ious = box_iou(boxes_p, boxes_g)\n",
        "\n",
        "            order = torch.argsort(scores_p, descending=True)\n",
        "            used_g = set()\n",
        "            for pi in order.tolist():\n",
        "                if ious.size(1) == 0:\n",
        "                    break\n",
        "                iou_row = ious[pi]\n",
        "                cand_iou = iou_row.clone()\n",
        "                for gidx in used_g:\n",
        "                    cand_iou[gidx] = -1.0\n",
        "                gi = int(torch.argmax(cand_iou).item())\n",
        "                best_iou = float(iou_row[gi].item())\n",
        "                if best_iou < iou_thr:\n",
        "                    continue\n",
        "                used_g.add(gi)\n",
        "                matched_total += 1\n",
        "                if int(labels_p[pi]) == int(labels_g[gi]):\n",
        "                    matched_correct += 1\n",
        "\n",
        "    acc = (matched_correct / matched_total) if matched_total > 0 else 0.0\n",
        "\n",
        "    if was_training:\n",
        "        model.train()\n",
        "    return acc\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate_box_head_top1_acc(model, loader, device, desc=\"BoxHead Top-1\"):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    bg_argmax = 0\n",
        "\n",
        "    for images, targets in tqdm(loader, desc=desc, leave=False):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        img_list, targets_t = model.transform(images, targets)\n",
        "        features = model.backbone(img_list.tensors)\n",
        "        proposals = [t[\"boxes\"] for t in targets_t]\n",
        "        if all(p.numel() == 0 for p in proposals):\n",
        "            continue\n",
        "        img_sizes = img_list.image_sizes\n",
        "\n",
        "        box_feats = model.roi_heads.box_roi_pool(features, proposals, img_sizes)\n",
        "        if box_feats.numel() == 0:\n",
        "            continue\n",
        "        box_feats = model.roi_heads.box_head(box_feats)\n",
        "        class_logits, _ = model.roi_heads.box_predictor(box_feats)\n",
        "\n",
        "        C = class_logits.shape[1]\n",
        "        gt_labels = torch.cat([t[\"labels\"] for t in targets_t if t[\"boxes\"].numel() > 0], dim=0)\n",
        "\n",
        "        bg_argmax += (class_logits.argmax(dim=1) == 0).sum().item()\n",
        "\n",
        "        fg_logits = class_logits[:, 1:]\n",
        "        preds = fg_logits.argmax(dim=1) + 1\n",
        "\n",
        "        correct += (preds == gt_labels).sum().item()\n",
        "        total   += gt_labels.numel()\n",
        "\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def diagnose_classification_issue(model, val_loader, device, max_batches=10):\n",
        "    acc = evaluate_box_head_top1_acc(model, val_loader, device, desc=\"BoxHead Top-1 (diagnose)\")\n",
        "    print(f\"Box-head top1: {acc:.3f}\")\n",
        "    return acc\n",
        "\n",
        "\n",
        "def fit(model, optimizer, lr_sch, loaders, device,\n",
        "        epochs=10, accum_steps=2, save_path=\"mask_rcnn_wbc_best.pth\",\n",
        "        logs_dir: Path | None = None):\n",
        "\n",
        "    if logs_dir is None:\n",
        "        logs_dir = Path(\"logs\")\n",
        "    logs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "    best_val = float(\"inf\")\n",
        "\n",
        "    hist = {\"train_loss\": [], \"val_loss\": [], \"train_fg_top1\": [], \"val_fg_top1\": [], \"train_top1\": [], \"val_top1\": []}\n",
        "\n",
        "    csv_path = logs_dir / \"history.csv\"\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"epoch\",\"train_loss\",\"val_loss\",\"train_boxhead_top1\",\"val_boxhead_top1\",\"train_fg_top1\",\"val_fg_top1\"])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\\n\" + \"-\"*12)\n",
        "\n",
        "        if epoch < 10:\n",
        "            aug_p = 0.0\n",
        "        elif epoch < 20:\n",
        "            aug_p = 0.3\n",
        "        else:\n",
        "            aug_p = 0.5\n",
        "\n",
        "        train_loader = loaders[\"train\"]\n",
        "        if hasattr(train_loader.dataset.transforms.transforms[0], \"p\"):\n",
        "            train_loader.dataset.transforms.transforms[0].p = aug_p\n",
        "        print(f\"[Epoch {epoch+1}] Data Augmentation Probability = {aug_p}\")\n",
        "\n",
        "        train_logs = train_one_epoch(model, optimizer, loaders[\"train\"], device, scaler, accum_steps)\n",
        "        val_logs   = evaluate_losses(model, loaders[\"val\"], device)\n",
        "\n",
        "        train_fg_top1 = evaluate_fg_top1(model, loaders[\"train\"], device, iou_thr=0.5, score_thr=0.8, desc=\"Train(FG Top1)\")\n",
        "        val_fg_top1   = evaluate_fg_top1(model, loaders[\"val\"],   device, iou_thr=0.5, score_thr=0.8, desc=\"Val(FG Top1)\")\n",
        "\n",
        "        train_top1 = evaluate_box_head_top1_acc(model, loaders[\"train\"], device, desc=\"Train(BoxHead Top1)\")\n",
        "        val_top1   = evaluate_box_head_top1_acc(model, loaders[\"val\"],   device, desc=\"Val(BoxHead Top1)\")\n",
        "\n",
        "        lr_sch.step()\n",
        "\n",
        "        hist[\"train_loss\"].append(train_logs[\"loss\"])\n",
        "        hist[\"val_loss\"].append(val_logs[\"loss\"])\n",
        "        hist[\"train_fg_top1\"].append(train_fg_top1)\n",
        "        hist[\"val_fg_top1\"].append(val_fg_top1)\n",
        "        hist[\"train_top1\"].append(train_top1)\n",
        "        hist[\"val_top1\"].append(val_top1)\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] loss: {train_logs['loss']:.4f} (train)  {val_logs['loss']:.4f} (val)\")\n",
        "        print(f\"[Epoch {epoch+1}] box-head top1: {train_top1:.3f} (train)  {val_top1:.3f} (val)\")\n",
        "        print(f\"[Epoch {epoch+1}] FG top-1:      {train_fg_top1:.3f} (train)  {val_fg_top1:.3f} (val)\")\n",
        "\n",
        "        with open(csv_path, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch+1, train_logs[\"loss\"], val_logs[\"loss\"], train_top1, val_top1, train_fg_top1, val_fg_top1])\n",
        "\n",
        "        if val_logs[\"loss\"] < best_val:\n",
        "            best_val = val_logs[\"loss\"]\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Saved best model to {save_path}\")\n",
        "\n",
        "        torch.cuda.empty_cache(); gc.collect(); print()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(hist[\"train_loss\"], label=\"train\")\n",
        "    plt.plot(hist[\"val_loss\"], label=\"val\")\n",
        "    plt.title(\"Total Loss\"); plt.legend()\n",
        "    plt.savefig(logs_dir / \"loss_curve.png\", dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(hist[\"train_top1\"], label=\"train top-1\")\n",
        "    plt.plot(hist[\"val_top1\"],   label=\"val top-1\")\n",
        "    plt.title(\"Box-Head Top-1\"); plt.legend()\n",
        "    plt.savefig(logs_dir / \"box_head_top1_curve.png\", dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(hist[\"train_fg_top1\"], label=\"train fg top-1\")\n",
        "    plt.plot(hist[\"val_fg_top1\"],   label=\"val fg top-1\")\n",
        "    plt.title(\"FG Top-1\"); plt.legend()\n",
        "    plt.savefig(logs_dir / \"fg_top1_curve.png\", dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def main():\n",
        "    set_torch_threads(4)\n",
        "\n",
        "    data_dir = \"/content/drive/MyDrive/Thesis/MaskRCNN/TestData_new\"\n",
        "    train_split = os.path.join(data_dir, \"train\")\n",
        "    val_split   = os.path.join(data_dir, \"val\")\n",
        "\n",
        "    current_aug_p = 0.0\n",
        "    train_ds = CocoInstanceDataset(train_split, transforms=get_transform(train=True, aug_prob=current_aug_p))\n",
        "    val_ds   = CocoInstanceDataset(val_split,   transforms=get_transform(train=False))\n",
        "\n",
        "    num_classes = len(train_ds.classes)\n",
        "    print(\"Classes:\", train_ds.classes, \" -> num_classes =\", num_classes)\n",
        "\n",
        "    loaders = {\n",
        "        \"train\": DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2,\n",
        "                            collate_fn=collate_fn, pin_memory=torch.cuda.is_available()),\n",
        "        \"val\":   DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=2,\n",
        "                            collate_fn=collate_fn, pin_memory=torch.cuda.is_available())\n",
        "    }\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = get_mask_rcnn_vgg(\"vgg13\", num_classes=num_classes, trainable_layers=5)\n",
        "    model = enhance_classification_head(model, num_classes)\n",
        "    model = optimize_model_parameters(model)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer, lr_sch = get_optimizer_and_scheduler(model, lr=0.003)\n",
        "\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
        "    logs_dir = Path(\"/content/drive/MyDrive/maskrcnn_logs\") / f\"{timestamp}_maskrcnn_VGG13\"\n",
        "    logs_dir.mkdir(parents=True, exist_ok=True)\n",
        "    save_path = logs_dir / \"mask_rcnn_VGG13_best.pth\"\n",
        "    print(f\"[Logger] logs dir: {logs_dir}\")\n",
        "\n",
        "    diagnose_classification_issue(model, loaders[\"val\"], device)\n",
        "\n",
        "    model = fit(model, optimizer, lr_sch, loaders, device,\n",
        "                epochs=50, accum_steps=4,\n",
        "                save_path=save_path,\n",
        "                logs_dir=logs_dir)\n",
        "\n",
        "    print(\"Training done.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}